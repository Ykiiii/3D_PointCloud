{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICP 点云精配准\n",
    "本教程演示了ICP（迭代最接近点）配准算法。多年来，它一直是研究和工业领域中几何配准的主流。\n",
    "输入是两个点云和一个初始变换，该变换将源点云与目标点云大致对齐。输出是一个细化的变换，将两个点云紧密地对齐。\n",
    "在配准过程中，一个辅助函数draw_registration_result将对齐情况可视化。\n",
    "在本教程中，我们展示了两个ICP变体，点对点ICP和点对平面ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import open3d_example as o3de\n",
    "import numpy as np\n",
    "import copy,time,re,os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辅助的可视化函数\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 1])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4459,\n",
    "                                      front=[0.9288, -0.2951, -0.2242],\n",
    "                                      lookat=[1.6784, 2.0612, 1.4451],\n",
    "                                      up=[-0.3402, -0.9189, -0.1996])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作算法输入\n",
    "# 从两个文件中读取一个源点云和一个目标点云。给出了一个粗略的变换。\n",
    "# 最初的对齐方式通常是通过全局配准算法得到的。例子见全局配准。\n",
    "\n",
    "source = o3d.io.read_point_cloud(\"PointCloudData\\\\DemoICPPointClouds\\\\cloud_bin_0.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"PointCloudData\\\\DemoICPPointClouds\\\\cloud_bin_1.pcd\")\n",
    "threshold = 0.02\n",
    "trans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n",
    "                         [-0.139, 0.967, -0.215, 0.7],\n",
    "                         [0.487, 0.255, 0.835, -1.4], \n",
    "                         [0.0, 0.0, 0.0, 1.0]])\n",
    "draw_registration_result(source, target, trans_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数 evaluate_registration 计算两个主要指标。\n",
    "# fitness，衡量重叠的区域(# inlier correspondences / # of points in target)。越高越好。\n",
    "# inlier_rmse, 衡量所有inlier对应点的RMSE。越低越好。\n",
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "  source, target, threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 点对点 ICP\n",
    "一般来说，ICP算法经过两步迭代。\n",
    "\n",
    "1. 从目标点云P和用当前变换矩阵T变换的源点云Q中找到对应集K={(p,q)}。\n",
    "2. 通过最小化定义在对应集K上的目标函数E(T)来更新变换T。\n",
    "\n",
    "不同的ICP变体使用不同的目标函数E（T）\n",
    "\n",
    "TransformationEstimationPointToPoint类提供了计算点对点ICP目标的残差和雅各布矩阵的函数。函数registration_icp将其作为参数，并运行点对点ICP来获得结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认情况下，registration_icp运行到收敛或达到最大迭代次数（默认为30次）。\n",
    "# 可以改变它以允许更多的计算时间并进一步改善结果。\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "    o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 点对面 ICP\n",
    "点对平面的ICP算法[ChenAndMedioni1992]使用一个不同的目标函数\n",
    "\n",
    "其中np是p点的法线。[Rusinkiewicz2001]表明，点到平面的ICP算法比点到点的ICP算法具有更快的收敛速度。\n",
    "\n",
    "registration_icp被调用时有一个不同的参数TransformationEstimationPointToPlane。在内部，这个类实现了计算点对平面ICP目标的残差和雅各布矩阵的函数。\n",
    "\n",
    "**点对平面的ICP算法使用点法线。在本教程中，我们从文件中加载法线。如果没有给出法线，可以用顶点法线估计来计算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Apply point-to-plane ICP\")\n",
    "reg_p2l = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "print(reg_p2l)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2l.transformation)\n",
    "draw_registration_result(source, target, reg_p2l.transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鲁棒核ICP\n",
    "本教程演示了鲁棒核在剔除异常值方面的使用。在这个特定的教程中，我们将使用ICP（迭代最接近点）配准算法作为我们要处理异常值的目标问题。即便如此，该理论也适用于任何特定的优化问题，而不仅仅是ICP。目前，鲁棒的核子只在PointToPlane ICP中实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化\n",
    "初始对齐通常由全局配准算法获得。例子见全局配准。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4459,\n",
    "                                      front=[0.9288, -0.2951, -0.2242],\n",
    "                                      lookat=[1.6784, 2.0612, 1.4451],\n",
    "                                      up=[-0.3402, -0.9189, -0.1996])\n",
    "source = o3d.io.read_point_cloud(\"PointCloudData\\\\DemoICPPointClouds\\\\cloud_bin_0.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"PointCloudData\\\\DemoICPPointClouds\\\\cloud_bin_1.pcd\")\n",
    "# threshold = 0.2\n",
    "trans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n",
    "                         [-0.139, 0.967, -0.215, 0.7],\n",
    "                         [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\n",
    "draw_registration_result(source, target, trans_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了更好地展示在配准中使用鲁棒核的优势，我们在源点云中加入一些人工生成的高斯噪声。\n",
    "def apply_noise(pcd, mu, sigma):\n",
    "    noisy_pcd = copy.deepcopy(pcd)\n",
    "    points = np.asarray(noisy_pcd.points)\n",
    "    points += np.random.normal(mu, sigma, size=points.shape)\n",
    "    noisy_pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    return noisy_pcd\n",
    "\n",
    "\n",
    "mu, sigma = 0, 0.1  # mean and standard deviation\n",
    "source_noisy = apply_noise(source, mu, sigma)\n",
    "\n",
    "print(\"Source PointCloud + noise:\")\n",
    "o3d.visualization.draw_geometries([source_noisy],\n",
    "                                  zoom=0.4459,\n",
    "                                  front=[0.353, -0.469, -0.809],\n",
    "                                  lookat=[2.343, 2.217, 1.809],\n",
    "                                  up=[-0.097, -0.879, 0.467])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 普通icp对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 普通icp\n",
    "threshold = 0.02\n",
    "print(\"Vanilla point-to-plane ICP, threshold={}:\".format(threshold))\n",
    "p2l = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "reg_p2l = o3d.pipelines.registration.registration_icp(source_noisy, target,\n",
    "                                                      threshold, trans_init,\n",
    "                                                      p2l)\n",
    "\n",
    "print(reg_p2l)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2l.transformation)\n",
    "draw_registration_result(source, target, reg_p2l.transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整普通ICP\n",
    "# 鉴于我们现在处理的是高斯噪声，我们可以尝试增加阈值来搜索最近的邻居，以改善配准结果。\n",
    "# 我们可以看到，在这些条件下，如果没有一个健壮的内核，传统的ICP没有机会处理离群值\n",
    "threshold = 1.0\n",
    "print(\"Vanilla point-to-plane ICP, threshold={}:\".format(threshold))\n",
    "p2l = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "reg_p2l = o3d.pipelines.registration.registration_icp(source_noisy, target,\n",
    "                                                      threshold, trans_init,\n",
    "                                                      p2l)\n",
    "\n",
    "print(reg_p2l)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2l.transformation)\n",
    "draw_registration_result(source, target, reg_p2l.transformation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 鲁棒核ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 鲁棒核ICP\n",
    "# 使用相同的阈值=1.0和一个稳健的内核，我们可以正确地配准两个点云。\n",
    "threshold = 1\n",
    "print(\"Robust point-to-plane ICP, threshold={}:\".format(threshold))\n",
    "loss = o3d.pipelines.registration.TukeyLoss(k=sigma)\n",
    "print(\"Using robust loss:\", loss)\n",
    "p2l = o3d.pipelines.registration.TransformationEstimationPointToPlane(loss)\n",
    "reg_p2l = o3d.pipelines.registration.registration_icp(source_noisy, target,\n",
    "                                                      threshold, trans_init,\n",
    "                                                      p2l)\n",
    "print(reg_p2l)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2l.transformation)\n",
    "draw_registration_result(source, target, reg_p2l.transformation)\n",
    "\n",
    "# 对于参数k，我们将其设置为与噪声模型的标准偏差k=σ相匹配。\n",
    "# Robust Kernels中使用的参数k通常被选为与输入数据的噪声模型的标准差相匹配。\n",
    "# 在这个意义上，k是区分离群者/离群者的工具。\n",
    "# 尽管这在现实世界的数据中并不总是那么容易定义，但对于合成数据来说，为了说明鲁棒核的好处，这很容易固定下来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 彩色点云配准\n",
    "本教程演示了一个ICP变体，它同时使用几何和颜色进行配准。它实现了[Park2017]的算法。颜色信息锁定了沿切线平面的对齐。因此，这个算法比之前的点云配准算法更准确、更稳健，而运行速度与ICP配准的速度相当。本教程使用ICP配准的符号。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result_original_color(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target],\n",
    "                                      zoom=0.5,\n",
    "                                      front=[-0.2458, -0.8088, 0.5342],\n",
    "                                      lookat=[1.7745, 2.2305, 0.9787],\n",
    "                                      up=[0.3109, -0.5878, -0.7468])\n",
    "print(\"1. Load two point clouds and show initial pose\")\n",
    "# demo_colored_icp_pcds = o3d.data.DemoColoredICPPointClouds()\n",
    "# source = o3d.io.read_point_cloud(demo_colored_icp_pcds.paths[0])\n",
    "# target = o3d.io.read_point_cloud(demo_colored_icp_pcds.paths[1])\n",
    "\n",
    "source = o3d.io.read_point_cloud(\"PointCloudData\\\\DemoICPPointClouds\\\\cloud_bin_0.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"PointCloudData\\\\DemoICPPointClouds\\\\cloud_bin_1.pcd\")\n",
    "# draw initial alignment\n",
    "current_transformation = np.identity(4)\n",
    "draw_registration_result_original_color(source, target, current_transformation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 点对面的ICP(作对比，与上同)\n",
    "首先运行点对平面ICP作为一个基准方法。下面的可视化图显示了错位的绿色三角形纹理。这是因为几何约束并不能阻止两个平面的滑移。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to plane ICP\n",
    "current_transformation = np.identity(4)# 这里更改了初始矩阵，导致效果差\n",
    "print(\"2. Point-to-plane ICP registration is applied on original point\")\n",
    "print(\"   clouds to refine the alignment. Distance threshold 0.02.\")\n",
    "result_icp = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, 0.02, current_transformation,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "print(result_icp)\n",
    "draw_registration_result_original_color(source, target,\n",
    "                                        result_icp.transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 彩色点云配准\n",
    "（也不是很准）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colored pointcloud registration\n",
    "# This is implementation of following paper\n",
    "# J. Park, Q.-Y. Zhou, V. Koltun,\n",
    "# Colored Point Cloud Registration Revisited, ICCV 2017\n",
    "voxel_radius = [0.04, 0.02, 0.01]\n",
    "max_iter = [50, 30, 14]\n",
    "current_transformation = np.identity(4)\n",
    "print(\"3. Colored point cloud registration\")\n",
    "for scale in range(3):\n",
    "    iter = max_iter[scale]\n",
    "    radius = voxel_radius[scale]\n",
    "    print([iter, radius, scale])\n",
    "\n",
    "    print(\"3-1. Downsample with a voxel size %.2f\" % radius)\n",
    "    source_down = source.voxel_down_sample(radius)\n",
    "    target_down = target.voxel_down_sample(radius)\n",
    "\n",
    "    print(\"3-2. Estimate normal.\")\n",
    "    source_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "    target_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "\n",
    "    print(\"3-3. Applying colored point cloud registration\")\n",
    "    result_icp = o3d.pipelines.registration.registration_colored_icp(\n",
    "        source_down, target_down, radius, current_transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                          relative_rmse=1e-6,\n",
    "                                                          max_iteration=iter))\n",
    "    current_transformation = result_icp.transformation\n",
    "    print(result_icp)\n",
    "draw_registration_result_original_color(source, target,\n",
    "                                        result_icp.transformation)\n",
    "# 总共有3层多分辨率的点云是用voxel_down_sample创建的。\n",
    "# 法线是通过顶点法线估计来计算的。\n",
    "# lambda_geometric是registration_colored_icp的一个可选参数，它决定了λ∈[0,1]的整体能量λEG+(1-λ)EC。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全局配准Global registration\n",
    "ICP配准和彩色点云配准都被称为局部配准方法，因为它们依赖于粗略的对齐作为初始化。本教程展示了另一类配准方法，被称为全局配准。这个系列的算法不需要对齐的初始化。它们通常产生不太严格的对齐结果，并被用作局部方法的初始化\n",
    "## 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化，这个辅助函数将转换后的源点云与目标点云一起可视化。\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取几何特征\n",
    "# 对点云进行降样，估计法线，然后为每个点计算一个FPFH特征。\n",
    "# FPFH特征是一个33维的向量，描述了一个点的局部几何属性。\n",
    "# 33维空间中的近邻查询可以返回具有相似的局部几何结构的点\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入\n",
    "# 下面的代码从两个文件中读取源点云和目标点云。它们与一个单位矩阵错位作为变换。\n",
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "\n",
    "    # demo_icp_pcds = o3d.data.DemoICPPointClouds()\n",
    "    # source = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\n",
    "    # target = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\n",
    "    source = o3d.io.read_point_cloud(\"PointCloudData\\\\DemoICPPointClouds\\\\cloud_bin_0.pcd\")\n",
    "    target = o3d.io.read_point_cloud(\"PointCloudData\\\\DemoICPPointClouds\\\\cloud_bin_1.pcd\")\n",
    "\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh\n",
    "voxel_size = 0.05  # means 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(\n",
    "    voxel_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ransac迭代全局配准\n",
    "我们使用RANSAC进行全局配准。在每个RANSAC迭代中，从源点云中挑选ransac_n个随机点。它们在目标点云中的对应点是通过查询33维FPFH特征空间中的最近邻居来检测的。剪枝步骤采取快速剪枝算法，以快速拒绝早期的错误匹配。\n",
    "\n",
    "Open3D提供了以下剪枝算法:\n",
    "\n",
    "- CorrespondenceCheckerBasedOnDistance检查对齐的点云是否接近（小于指定阈值）。\n",
    "- CorrespondenceCheckerBasedOnEdgeLength检查从源和目标对应关系中单独绘制的任何两条任意边（由两个顶点形成的线）的长度是否相似。本教程检查||edgesource||>0.9⋅||edgetarget||和||edgetarget||>0.9⋅|edgesource||为真。\n",
    "- CorrespondenceCheckerBasedOnNormal考虑任何对应关系的顶点法线亲和力。它计算两个法线向量的点积。它采用一个弧度值作为阈值。 ` 只有通过剪枝步骤的匹配才会被用来计算转换，并在整个点云上进行验证。核心功能是基于特征匹配的配准登记\n",
    "  \n",
    "只有通过剪枝步骤的匹配才用于计算转换，并在整个点云上进行验证。核心函数是registration_ransac_based_on_feature_matching。这个函数最重要的超参数是RANSACConvergenceCriteria。它定义了RANSAC迭代的最大次数和置信概率。这两个数字越大，表示结果越准确，但也意味着算法花费的时间越长。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "print(result_ransac)\n",
    "draw_registration_result(source_down, target_down, result_ransac.transformation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 点对面ICP局部细化\n",
    "由于性能的原因，全局配准只在严重下采样的点云上进行。其结果也是不紧密的。我们使用点对平面的ICP来进一步细化配准。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_ransac.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    return result\n",
    "result_icp = refine_registration(source, target, source_fpfh, target_fpfh,\n",
    "                                 voxel_size)\n",
    "print(result_icp)\n",
    "draw_registration_result(source, target, result_icp.transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 快速全局配准\n",
    "由于无数的模型建议和评估，基于RANSAC的全局配准解决方案可能需要很长的时间。[Zhou2016]引入了一种更快的方法，快速优化少数对应关系的线程权重。由于每次迭代都不涉及模型建议和评估，[Zhou2016]中提出的方法可以节省大量的计算时间。\n",
    "\n",
    "本教程将基于RANSAC的全局配准的运行时间与[Zhou2016]的实现进行了比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们使用与上面的全局配准例子相同的输入\n",
    "voxel_size = 0.05  # means 5cm for the dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = \\\n",
    "        prepare_dataset(voxel_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ransac迭代全局配准的耗时\n",
    "start = time.time()\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "print(\"Global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "print(result_ransac)\n",
    "draw_registration_result(source_down, target_down, result_ransac.transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速全局配准\n",
    "def execute_fast_global_registration(source_down, target_down, source_fpfh,\n",
    "                                     target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    print(\":: Apply fast global registration with distance threshold %.3f\" \\\n",
    "            % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh,\n",
    "        o3d.pipelines.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=distance_threshold))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速全局配准的耗时\n",
    "start = time.time()\n",
    "result_fast = execute_fast_global_registration(source_down, target_down,\n",
    "                                               source_fpfh, target_fpfh,\n",
    "                                               voxel_size)\n",
    "print(\"Fast global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "print(result_fast)\n",
    "draw_registration_result(source_down, target_down, result_fast.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGR快速全局配准\n",
    "# 除了基于fpfh特征的FGR之外，还可以通过registration_fgr_based_on_correspondence使用基于通信的FGR执行全局配准。\n",
    "# 如果您的通信前端与FPFH不同，则此方法很有用，但您仍然希望在给定一组假定通信的情况下使用FGR。它可以被调用\n",
    "def execute_fast_global_registration(source_down, target_down, \n",
    "                                     correspondence_set, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    print(\":: Apply fast global registration with distance threshold %.3f\" \\\n",
    "            % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_fgr_based_on_correspondence(\n",
    "        source_down, target_down, correspondence_set,\n",
    "        o3d.pipelines.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=distance_threshold))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多向配准Multiway registration\n",
    "多向配准是指在一个全局空间中对多个几何体进行配准的过程。通常输入是一组几何体（例如，点云或RGBD图像）{Pi}。输出是一组刚性变换{Ti}，从而使变换后的点云{TiPi}在全局空间中保持一致。\n",
    "\n",
    "Open3D通过姿态图优化实现了多向配准。后台实现了[Choi2015]中提出的技术。\n",
    "## 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从文件中读取三个点云。这些点云被降低采样率，并一起可视化。它们是错位的\n",
    "def load_point_clouds(voxel_size=0.0):\n",
    "    pcds = []\n",
    "    DataFolder = \"PointCloudData\\\\DemoICPPointClouds\"\n",
    "    for path in os.listdir(DataFolder):\n",
    "        pcd = o3d.io.read_point_cloud(DataFolder+\"\\\\\"+path)\n",
    "        pcd_down = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "        pcds.append(pcd_down)\n",
    "    return pcds\n",
    "voxel_size = 0.02\n",
    "pcds_down = load_point_clouds(voxel_size)\n",
    "o3d.visualization.draw_geometries(pcds_down,\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配准成位姿图\n",
    "\n",
    "位姿图有两个关键元素：节点和边。一个节点是一块与位姿矩阵Ti相关的几何体Pi，它将Pi转换到全局空间。集合{Ti}是要优化的未知变量。PoseGraph.nodes是一个PoseGraphNode的列表。我们设定全局空间为P0的空间。因此T0是身份矩阵。其他的位姿矩阵是通过累积相邻节点之间的变换来初始化的。相邻的节点通常有很大的重叠，可以用点对平面的ICP进行配准。\n",
    "\n",
    "位姿图的边连接着两个重叠的节点（几何体的碎片）。每条边都包含一个变换矩阵Ti,j，将源几何体Pi与目标几何体Pj对齐。本教程使用点对平面ICP来估计变换。在更复杂的情况下，这个成对的配准问题应该通过全局配准来解决。\n",
    "\n",
    "[Choi2015]已经观察到成对配准是容易出错的。错误的成对配准可能会超过正确配准的对数。因此，他们将位姿图的边缘划分为两类。位姿图边连接着时间上接近的、相邻的节点。像ICP这样的局部配准算法可以可靠地对齐它们。环形闭合边连接任何非相邻的节点。对齐是通过全局配准找到的，可靠性较低。在Open3D中，这两类边缘是由PoseGraphEdge初始化器中的不确定参数来区分的。\n",
    "\n",
    "除了变换矩阵Ti之外，用户还可以为每条边设置一个信息矩阵Λi。如果Λi是用函数get_information_matrix_from_point_clouds设置的，该位姿图边缘的损失近似于两个节点之间相应集合的RMSE，有一个线程权重。详情请参考[Choi2015]中的公式（3）到（9）以及Redwood配准基准。\n",
    "\n",
    "该脚本创建了一个有三个节点和三条边的位姿图。在这些边中，有两条是测距边（uncertain = False），一条是循环闭合边（uncertain = True）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_registration(source, target):\n",
    "    print(\"Apply point-to-plane ICP\")\n",
    "    icp_coarse = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, max_correspondence_distance_coarse, np.identity(4),\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    icp_fine = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, max_correspondence_distance_fine,\n",
    "        icp_coarse.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    transformation_icp = icp_fine.transformation\n",
    "    information_icp = o3d.pipelines.registration.get_information_matrix_from_point_clouds(\n",
    "        source, target, max_correspondence_distance_fine,\n",
    "        icp_fine.transformation)\n",
    "    return transformation_icp, information_icp\n",
    "\n",
    "\n",
    "def full_registration(pcds, max_correspondence_distance_coarse,\n",
    "                      max_correspondence_distance_fine):\n",
    "    pose_graph = o3d.pipelines.registration.PoseGraph()\n",
    "    odometry = np.identity(4)\n",
    "    pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(odometry))\n",
    "    n_pcds = len(pcds)\n",
    "    for source_id in range(n_pcds):\n",
    "        for target_id in range(source_id + 1, n_pcds):\n",
    "            transformation_icp, information_icp = pairwise_registration(\n",
    "                pcds[source_id], pcds[target_id])\n",
    "            print(\"Build o3d.pipelines.registration.PoseGraph\")\n",
    "            if target_id == source_id + 1:  # odometry case\n",
    "                odometry = np.dot(transformation_icp, odometry)\n",
    "                pose_graph.nodes.append(\n",
    "                    o3d.pipelines.registration.PoseGraphNode(\n",
    "                        np.linalg.inv(odometry)))\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp,\n",
    "                                                             information_icp,\n",
    "                                                             uncertain=False))\n",
    "            else:  # loop closure case\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n",
    "                                                             target_id,\n",
    "                                                             transformation_icp,\n",
    "                                                             information_icp,\n",
    "                                                             uncertain=True))\n",
    "    return pose_graph\n",
    "print(\"Full registration ...\")\n",
    "max_correspondence_distance_coarse = voxel_size * 15\n",
    "max_correspondence_distance_fine = voxel_size * 1.5\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    pose_graph = full_registration(pcds_down,\n",
    "                                   max_correspondence_distance_coarse,\n",
    "                                   max_correspondence_distance_fine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimizing PoseGraph ...\")\n",
    "option = o3d.pipelines.registration.GlobalOptimizationOption(\n",
    "    max_correspondence_distance=max_correspondence_distance_fine,\n",
    "    edge_prune_threshold=0.25,\n",
    "    reference_node=0)\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    o3d.pipelines.registration.global_optimization(\n",
    "        pose_graph,\n",
    "        o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "        o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n",
    "        option)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全局优化在位姿图上执行两次。第一遍对原始位姿图的位姿进行优化，考虑到所有的边，并尽力区分不确定的边之间的错误排列。这些错误的排列具有较小的线程权重，它们在第一遍之后被修剪掉。第二遍运行时不考虑它们，并产生一个紧密的全局对齐。在这个例子中，所有的边都被认为是真正的对齐，因此第二遍立即终止。\n",
    "\n",
    "## 可视化优化\n",
    "\n",
    "转换后的点云被列出，并使用draw_geometries进行可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transform points and display\")\n",
    "for point_id in range(len(pcds_down)):\n",
    "    print(pose_graph.nodes[point_id].pose)\n",
    "    pcds_down[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "o3d.visualization.draw_geometries(pcds_down,\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并点云\n",
    "PointCloud有一个方便的操作符+，可以将两个点云合并成一个。在下面的代码中，合并后的点使用voxel_down_sample进行了统一的重采样。这是建议在合并点云后进行的后处理，因为它可以缓解重复的或过度密集的点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds = load_point_clouds(voxel_size)\n",
    "pcd_combined = o3d.geometry.PointCloud()\n",
    "for point_id in range(len(pcds)):\n",
    "    pcds[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "    pcd_combined += pcds[point_id]\n",
    "pcd_combined_down = pcd_combined.voxel_down_sample(voxel_size=voxel_size)\n",
    "o3d.io.write_point_cloud(\"test\\\\multiway_registration.pcd\", pcd_combined_down)\n",
    "o3d.visualization.draw_geometries([pcd_combined_down],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGBD集成，从RGBD重建mesh\n",
    "Open3D实现了一个可扩展的RGBD图像整合算法。该算法是基于[Curless1996]和[Newcombe2011]中提出的技术。为了支持大型场景，我们在ElasticReconstruction中使用了Integrater中引入的分层散列结构。\n",
    "\n",
    "## 从.log文件中读取轨迹\n",
    "\n",
    "本教程使用函数read_trajectory从.log文件中读取摄像机的轨迹。一个.log文件的样本如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CameraPose:\n",
    "\n",
    "    def __init__(self, meta, mat):\n",
    "        self.metadata = meta\n",
    "        self.pose = mat\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Metadata : ' + ' '.join(map(str, self.metadata)) + '\\n' + \\\n",
    "            \"Pose : \" + \"\\n\" + np.array_str(self.pose)\n",
    "\n",
    "\n",
    "def read_trajectory(filename):\n",
    "    traj = []\n",
    "    with open(filename, 'r') as f:\n",
    "        metastr = f.readline()\n",
    "        while metastr:\n",
    "            metadata = list(map(int, metastr.split()))\n",
    "            mat = np.zeros(shape=(4, 4))\n",
    "            for i in range(4):\n",
    "                matstr = f.readline()\n",
    "                mat[i, :] = np.fromstring(matstr, dtype=float, sep=' \\t')\n",
    "            traj.append(CameraPose(metadata, mat))\n",
    "            metastr = f.readline()\n",
    "    return traj\n",
    "# redwood_rgbd = o3d.data.SampleRedwoodRGBDImages()\n",
    "camera_poses = read_trajectory(\"RGBD_Data\\\\SampleRedwoodRGBDImages\\\\trajectory.log\")\n",
    "print(camera_poses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSDF体积的集成\n",
    "\n",
    "Open3D提供两种类型的TSDF体积。UniformTSDFVolume和ScalableTSDFVolume。推荐使用后者，因为它使用分层结构，从而支持更大的场景。\n",
    "\n",
    "voxel_length = 4.0 / 512.0意味着TSDF体积的单个体素尺寸是4.0m/512.0=7.8125mm。降低这个值可以得到高分辨率的TSDF体积，但积分结果容易受到深度噪声的影响。 sdf_trunc = 0.04 指定有符号距离函数（SDF）的截断值。当color_type = TSDFVolumeColorType.RGB8时，8位RGB颜色也被整合为TSDF体积的一部分。当color_type = TSDFVolumeColorType.Gray32和convert_rgb_to_intensity = True时，浮点数类型的强度可以被整合。颜色整合的灵感来自于PCL。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "    voxel_length=4.0 / 512.0,\n",
    "    sdf_trunc=0.04,\n",
    "    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n",
    "\n",
    "\n",
    "DataFolder = \"RGBD_Data/SampleRedwoodRGBDImages\"\n",
    "redwood_rgbd_color_paths = [DataFolder+\"/color/\"+os.path.relpath(i) for i in os.listdir(DataFolder+\"/color\")]\n",
    "redwood_rgbd_depth_paths = [DataFolder+\"/depth/\"+os.path.relpath(i) for i in os.listdir(DataFolder+\"/depth\")]\n",
    "for i in range(len(camera_poses)):\n",
    "    print(\"Integrate {:d}-th image into the volume.\".format(i))\n",
    "    color = o3d.io.read_image(redwood_rgbd_color_paths[i])\n",
    "    depth = o3d.io.read_image(redwood_rgbd_depth_paths[i])\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color, depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "    volume.integrate(\n",
    "        rgbd,\n",
    "        o3d.camera.PinholeCameraIntrinsic(\n",
    "            o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault),\n",
    "        np.linalg.inv(camera_poses[i].pose))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取mesh\n",
    "网格提取采用行进立方体算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extract a triangle mesh from the volume and visualize it.\")\n",
    "mesh = volume.extract_triangle_mesh()\n",
    "mesh.compute_vertex_normals()\n",
    "# mesh.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "o3d.visualization.draw_geometries([mesh],\n",
    "                                  front=[0.9292, 0.3531, -0.1083],\n",
    "                                  lookat=[-1.9787, 0.5713, 2.5180],\n",
    "                                  up=[-0.3502, 0.9356, 0.0460],\n",
    "                                  zoom=0.56)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGBD里程计\n",
    "一个RGBD里程计可以找到两个连续的RGBD图像对之间的相机运动。输入是RGBDImage的两个实例。输出是以刚体变换的形式出现的运动。Open3D实现了[Steinbrucker2011]和[Park2017]的方法。\n",
    "## 读取相机内参\n",
    "我们首先从一个json文件中读取相机的内在矩阵\n",
    "\n",
    "注意: Open3D中的很多小数据结构都可以从json文件中读取/写入。这包括相机内在属性、相机轨迹、位姿图等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinhole_camera_intrinsic = o3d.io.read_pinhole_camera_intrinsic(\n",
    "    \"RGBD_Data\\\\SampleRedwoodRGBDImages\\\\camera_primesense.json\")\n",
    "print(pinhole_camera_intrinsic.intrinsic_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取RGBD图像\n",
    "\n",
    "这个代码块读取了两对Redwood格式的RGBD图像。我们参考Redwood数据集以获得全面的解释。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFolder = \"RGBD_Data/SampleRedwoodRGBDImages\"\n",
    "redwood_rgbd_color_paths = [DataFolder+\"/color/\"+os.path.relpath(i) for i in os.listdir(DataFolder+\"/color\")]\n",
    "redwood_rgbd_depth_paths = [DataFolder+\"/depth/\"+os.path.relpath(i) for i in os.listdir(DataFolder+\"/depth\")]\n",
    "\n",
    "source_color = o3d.io.read_image(redwood_rgbd_color_paths[0])\n",
    "source_depth = o3d.io.read_image(redwood_rgbd_depth_paths[0])\n",
    "target_color = o3d.io.read_image(redwood_rgbd_color_paths[1])\n",
    "target_depth = o3d.io.read_image(redwood_rgbd_depth_paths[1])\n",
    "source_rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    source_color, source_depth)\n",
    "target_rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    target_color, target_depth)\n",
    "target_pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    target_rgbd_image, pinhole_camera_intrinsic)\n",
    "# 注意: Open3D假定彩色图像和深度图像是同步的，并登记在同一坐标框架内。这通常可以通过打开RGBD相机设置中的同步和注册功能来实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从两个RGBD图像对中计算里程数\n",
    "这个代码块调用两个不同的RGBD测距方法。第一个是来自[Steinbrucker2011]。它最小化了对齐图像的照片一致性。第二个是来自[Park2017]。除了照片一致性之外，它还实现了对几何的约束。两个函数的运行速度相似，但在我们对基准数据集的测试中，[Park2017]更准确，因此是推荐的方法。\n",
    "\n",
    "OdometryOption()中有几个参数:\n",
    "\n",
    "- minimum_correspondence_ratio。对齐后，测量两个RGBD图像的重叠率。如果两幅RGBD图像的重叠区域小于指定的比率，那么dometry模块就认为这是一个失败的案例。\n",
    "\n",
    "- max_depth_diff: 在深度图像领域，如果两个对齐的像素的深度差小于指定的值，它们就被认为是一个对应关系。较大的值会引起更积极的搜索，但容易产生不稳定的结果。\n",
    "\n",
    "- min_depth和max_depth。小于或大于指定深度值的像素被忽略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = o3d.pipelines.odometry.OdometryOption()\n",
    "odo_init = np.identity(4)\n",
    "print(option)\n",
    "# 两种方法\n",
    "[success_color_term, trans_color_term,\n",
    " info] = o3d.pipelines.odometry.compute_rgbd_odometry(\n",
    "     source_rgbd_image, target_rgbd_image, pinhole_camera_intrinsic, odo_init,\n",
    "     o3d.pipelines.odometry.RGBDOdometryJacobianFromColorTerm(), option)\n",
    "[success_hybrid_term, trans_hybrid_term,\n",
    " info] = o3d.pipelines.odometry.compute_rgbd_odometry(\n",
    "     source_rgbd_image, target_rgbd_image, pinhole_camera_intrinsic, odo_init,\n",
    "     o3d.pipelines.odometry.RGBDOdometryJacobianFromHybridTerm(), option)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGBD图像对的可视化\n",
    "\n",
    "RGBD图像对被转换为点云并一起渲染。请注意，代表第一幅（源）RGBD图像的点云被转换为由里程计估计的变换。在这个转换之后，两个点云都被对齐了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两种算法的结果对比\n",
    "if success_color_term:\n",
    "    print(\"Using RGB-D Odometry\")\n",
    "    print(trans_color_term)\n",
    "    source_pcd_color_term = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "        source_rgbd_image, pinhole_camera_intrinsic)\n",
    "    source_pcd_color_term.transform(trans_color_term)\n",
    "    o3d.visualization.draw_geometries([target_pcd, source_pcd_color_term],\n",
    "                                      zoom=0.48,\n",
    "                                      front=[0.0999, -0.1787, -0.9788],\n",
    "                                      lookat=[0.0345, -0.0937, 1.8033],\n",
    "                                      up=[-0.0067, -0.9838, 0.1790])\n",
    "if success_hybrid_term:\n",
    "    print(\"Using Hybrid RGB-D Odometry\")\n",
    "    print(trans_hybrid_term)\n",
    "    source_pcd_hybrid_term = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "        source_rgbd_image, pinhole_camera_intrinsic)\n",
    "    source_pcd_hybrid_term.transform(trans_hybrid_term)\n",
    "    o3d.visualization.draw_geometries([target_pcd, source_pcd_hybrid_term],\n",
    "                                      zoom=0.48,\n",
    "                                      front=[0.0999, -0.1787, -0.9788],\n",
    "                                      lookat=[0.0345, -0.0937, 1.8033],\n",
    "                                      up=[-0.0067, -0.9838, 0.1790])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 颜色映射优化\n",
    "考虑将颜色映射到从深度摄像机重建的几何体上。由于颜色和深度帧不是完全一致的，使用颜色图像的纹理映射会导致颜色图的模糊。Open3D提供了由[Zhou2014]提出的颜色映射优化方法。下面的脚本显示了一个颜色贴图优化的例子。\n",
    "## 初始化\n",
    "下面的代码读取颜色和深度图像对，并制作rgbd_image。注意，convert_rgb_to_intensity标志是False。这是为了保留8位颜色通道，而不是使用单通道浮点型图像。\n",
    "\n",
    "在将RGBD图像应用于颜色地图优化之前，将其可视化始终是一个好的做法。debug_mode开关可以被设置为True，以实现RGBD图像的可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriangleMesh with 536872 points and 1033745 triangles. [RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data., RGBDImage of size \n",
      "Color image : 640x480, with 1 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data.] PinholeCameraTrajectory class.\n",
      "Access its data via camera.parameters.\n"
     ]
    }
   ],
   "source": [
    "def sorted_file(file_list):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(file_list, key=alphanum_key)\n",
    "\n",
    "rgbd_images = []\n",
    "DataFolder = \"RGBD_Data\\SampleFountainRGBDImages\"\n",
    "fountain_rgbd_dataset_color_paths = sorted_file([DataFolder+\"\\\\image\\\\\"+os.path.relpath(i) for i in os.listdir(DataFolder+\"\\\\image\")])\n",
    "fountain_rgbd_dataset_depth_paths = sorted_file([DataFolder+\"\\\\depth\\\\\"+os.path.relpath(i) for i in os.listdir(DataFolder+\"\\\\depth\")])\n",
    "for i in range(len(fountain_rgbd_dataset_depth_paths)):\n",
    "    depth = o3d.io.read_image(fountain_rgbd_dataset_depth_paths[i])\n",
    "    color = o3d.io.read_image(fountain_rgbd_dataset_color_paths[i])\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color, depth)\n",
    "    # print(rgbd_image)\n",
    "    rgbd_images.append(rgbd_image)\n",
    "# 读取摄像机轨迹和mesh\n",
    "camera_trajectory = o3d.io.read_pinhole_camera_trajectory(\n",
    "    DataFolder+\"\\\\scene\\\\key.log\")\n",
    "mesh = o3d.io.read_triangle_mesh(\n",
    "    DataFolder+\"\\\\scene\\\\integrated.ply\")\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "print(mesh, rgbd_images, camera_trajectory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RGBDImage of size \n",
       "Color image : 640x480, with 1 channels.\n",
       "Depth image : 640x480, with 1 channels.\n",
       "Use numpy.asarray to access buffer data."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgbd_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比，无优化\n",
    "为了直观地看到摄像机的位姿如何不利于颜色贴图，这段代码故意将迭代数设为0，这意味着没有优化。color_map_optimization使用相应的RGBD图像和摄像机位姿来绘制网格。没有优化，纹理图就会模糊不清。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: 不支持请求的转换操作。 \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: 句柄无效。 \n"
     ]
    }
   ],
   "source": [
    "# Before full optimization, let's visualize texture map\n",
    "# with given geometry, RGBD images, and camera poses.\n",
    "mesh, camera_trajectory = o3d.pipelines.color_map.run_rigid_optimizer(\n",
    "    mesh, rgbd_images, camera_trajectory,\n",
    "    o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=0))\n",
    "o3d.visualization.draw_geometries([mesh],\n",
    "                                  zoom=0.5399,\n",
    "                                  front=[0.0665, -0.1107, -0.9916],\n",
    "                                  lookat=[0.7353, 0.6537, 1.0521],\n",
    "                                  up=[0.0136, -0.9936, 0.1118])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 刚性优化\n",
    "下一步是优化摄像机的位姿，以获得一个清晰的颜色图。\n",
    "\n",
    "下面的代码为实际迭代设置了maximum_iteration = 300。\n",
    "\n",
    "残留误差意味着图像强度的不一致。较低的残差会导致更好的颜色地图质量。\n",
    "\n",
    "默认情况下，ColorMapOptimizationOption启用刚性优化。它对每个摄像机的6维位姿进行优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D DEBUG] [ColorMapOptimization] CreateUtilImagesFromRGBD\n",
      "[Open3D DEBUG] [ColorMapOptimization] CreateDepthBoundaryMasks\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 0/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 1/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 2/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 3/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 4/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 5/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 6/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 7/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 8/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 9/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 10/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 11/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 12/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 13/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 14/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 15/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 16/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 17/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 18/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 19/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 20/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 21/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 22/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 23/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 24/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 25/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 26/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 27/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 28/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 29/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 30/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 31/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 32/33\n",
      "[Open3D DEBUG] [ColorMapOptimization] CreateVertexAndImageVisibility\n",
      "[Open3D DEBUG] [cam 0]: 238774/536872 (44.47503%) vertices are visible\n",
      "[Open3D DEBUG] [cam 1]: 264228/536872 (49.21620%) vertices are visible\n",
      "[Open3D DEBUG] [cam 2]: 32910/536872 (6.12995%) vertices are visible\n",
      "[Open3D DEBUG] [cam 3]: 207076/536872 (38.57083%) vertices are visible\n",
      "[Open3D DEBUG] [cam 4]: 208953/536872 (38.92045%) vertices are visible\n",
      "[Open3D DEBUG] [cam 5]: 121789/536872 (22.68492%) vertices are visible\n",
      "[Open3D DEBUG] [cam 6]: 139892/536872 (26.05686%) vertices are visible\n",
      "[Open3D DEBUG] [cam 7]: 94112/536872 (17.52969%) vertices are visible\n",
      "[Open3D DEBUG] [cam 8]: 136523/536872 (25.42934%) vertices are visible\n",
      "[Open3D DEBUG] [cam 9]: 88157/536872 (16.42049%) vertices are visible\n",
      "[Open3D DEBUG] [cam 10]: 119823/536872 (22.31873%) vertices are visible\n",
      "[Open3D DEBUG] [cam 11]: 183991/536872 (34.27092%) vertices are visible\n",
      "[Open3D DEBUG] [cam 12]: 238849/536872 (44.48900%) vertices are visible\n",
      "[Open3D DEBUG] [cam 13]: 222246/536872 (41.39646%) vertices are visible\n",
      "[Open3D DEBUG] [cam 14]: 220761/536872 (41.11986%) vertices are visible\n",
      "[Open3D DEBUG] [cam 15]: 257217/536872 (47.91030%) vertices are visible\n",
      "[Open3D DEBUG] [cam 16]: 123058/536872 (22.92129%) vertices are visible\n",
      "[Open3D DEBUG] [cam 17]: 155657/536872 (28.99332%) vertices are visible\n",
      "[Open3D DEBUG] [cam 18]: 109616/536872 (20.41753%) vertices are visible\n",
      "[Open3D DEBUG] [cam 19]: 132968/536872 (24.76717%) vertices are visible\n",
      "[Open3D DEBUG] [cam 20]: 125766/536872 (23.42570%) vertices are visible\n",
      "[Open3D DEBUG] [cam 21]: 118639/536872 (22.09819%) vertices are visible\n",
      "[Open3D DEBUG] [cam 22]: 112538/536872 (20.96179%) vertices are visible\n",
      "[Open3D DEBUG] [cam 23]: 76603/536872 (14.26839%) vertices are visible\n",
      "[Open3D DEBUG] [cam 24]: 74932/536872 (13.95714%) vertices are visible\n",
      "[Open3D DEBUG] [cam 25]: 79252/536872 (14.76181%) vertices are visible\n",
      "[Open3D DEBUG] [cam 26]: 107727/536872 (20.06568%) vertices are visible\n",
      "[Open3D DEBUG] [cam 27]: 114058/536872 (21.24491%) vertices are visible\n",
      "[Open3D DEBUG] [cam 28]: 128703/536872 (23.97275%) vertices are visible\n",
      "[Open3D DEBUG] [cam 29]: 149558/536872 (27.85729%) vertices are visible\n",
      "[Open3D DEBUG] [cam 30]: 165234/536872 (30.77717%) vertices are visible\n",
      "[Open3D DEBUG] [cam 31]: 104629/536872 (19.48863%) vertices are visible\n",
      "[Open3D DEBUG] [cam 32]: 50546/536872 (9.41491%) vertices are visible\n",
      "[Open3D DEBUG] [ColorMapOptimization] Rigid Optimization\n",
      "[Open3D DEBUG] [Iteration 0001] \n",
      "[Open3D DEBUG] Residual error : 21627.768621 (avg : 0.004597)\n",
      "[Open3D DEBUG] [Iteration 0002] \n",
      "[Open3D DEBUG] Residual error : 21450.291135 (avg : 0.004559)\n",
      "[Open3D DEBUG] [Iteration 0003] \n",
      "[Open3D DEBUG] Residual error : 21273.138416 (avg : 0.004522)\n",
      "[Open3D DEBUG] [Iteration 0004] \n",
      "[Open3D DEBUG] Residual error : 21095.402935 (avg : 0.004484)\n",
      "[Open3D DEBUG] [Iteration 0005] \n",
      "[Open3D DEBUG] Residual error : 20918.021855 (avg : 0.004446)\n",
      "[Open3D DEBUG] [Iteration 0006] \n",
      "[Open3D DEBUG] Residual error : 20741.426493 (avg : 0.004409)\n",
      "[Open3D DEBUG] [Iteration 0007] \n",
      "[Open3D DEBUG] Residual error : 20565.403267 (avg : 0.004371)\n",
      "[Open3D DEBUG] [Iteration 0008] \n",
      "[Open3D DEBUG] Residual error : 20389.813726 (avg : 0.004334)\n",
      "[Open3D DEBUG] [Iteration 0009] \n",
      "[Open3D DEBUG] Residual error : 20214.920850 (avg : 0.004297)\n",
      "[Open3D DEBUG] [Iteration 0010] \n",
      "[Open3D DEBUG] Residual error : 20041.235823 (avg : 0.004260)\n",
      "[Open3D DEBUG] [Iteration 0011] \n",
      "[Open3D DEBUG] Residual error : 19868.146860 (avg : 0.004223)\n",
      "[Open3D DEBUG] [Iteration 0012] \n",
      "[Open3D DEBUG] Residual error : 19696.485295 (avg : 0.004186)\n",
      "[Open3D DEBUG] [Iteration 0013] \n",
      "[Open3D DEBUG] Residual error : 19526.257939 (avg : 0.004150)\n",
      "[Open3D DEBUG] [Iteration 0014] \n",
      "[Open3D DEBUG] Residual error : 19357.003360 (avg : 0.004114)\n",
      "[Open3D DEBUG] [Iteration 0015] \n",
      "[Open3D DEBUG] Residual error : 19188.390473 (avg : 0.004078)\n",
      "[Open3D DEBUG] [Iteration 0016] \n",
      "[Open3D DEBUG] Residual error : 19020.769133 (avg : 0.004043)\n",
      "[Open3D DEBUG] [Iteration 0017] \n",
      "[Open3D DEBUG] Residual error : 18853.673959 (avg : 0.004007)\n",
      "[Open3D DEBUG] [Iteration 0018] \n",
      "[Open3D DEBUG] Residual error : 18686.442401 (avg : 0.003972)\n",
      "[Open3D DEBUG] [Iteration 0019] \n",
      "[Open3D DEBUG] Residual error : 18520.269019 (avg : 0.003936)\n",
      "[Open3D DEBUG] [Iteration 0020] \n",
      "[Open3D DEBUG] Residual error : 18353.936846 (avg : 0.003901)\n",
      "[Open3D DEBUG] [Iteration 0021] \n",
      "[Open3D DEBUG] Residual error : 18188.177884 (avg : 0.003866)\n",
      "[Open3D DEBUG] [Iteration 0022] \n",
      "[Open3D DEBUG] Residual error : 18022.433052 (avg : 0.003831)\n",
      "[Open3D DEBUG] [Iteration 0023] \n",
      "[Open3D DEBUG] Residual error : 17857.744919 (avg : 0.003796)\n",
      "[Open3D DEBUG] [Iteration 0024] \n",
      "[Open3D DEBUG] Residual error : 17692.343942 (avg : 0.003760)\n",
      "[Open3D DEBUG] [Iteration 0025] \n",
      "[Open3D DEBUG] Residual error : 17527.758880 (avg : 0.003726)\n",
      "[Open3D DEBUG] [Iteration 0026] \n",
      "[Open3D DEBUG] Residual error : 17362.914704 (avg : 0.003690)\n",
      "[Open3D DEBUG] [Iteration 0027] \n",
      "[Open3D DEBUG] Residual error : 17197.453287 (avg : 0.003655)\n",
      "[Open3D DEBUG] [Iteration 0028] \n",
      "[Open3D DEBUG] Residual error : 17032.392931 (avg : 0.003620)\n",
      "[Open3D DEBUG] [Iteration 0029] \n",
      "[Open3D DEBUG] Residual error : 16866.963843 (avg : 0.003585)\n",
      "[Open3D DEBUG] [Iteration 0030] \n",
      "[Open3D DEBUG] Residual error : 16700.219471 (avg : 0.003550)\n",
      "[Open3D DEBUG] [Iteration 0031] \n",
      "[Open3D DEBUG] Residual error : 16533.402242 (avg : 0.003514)\n",
      "[Open3D DEBUG] [Iteration 0032] \n",
      "[Open3D DEBUG] Residual error : 16366.152025 (avg : 0.003479)\n",
      "[Open3D DEBUG] [Iteration 0033] \n",
      "[Open3D DEBUG] Residual error : 16197.984542 (avg : 0.003443)\n",
      "[Open3D DEBUG] [Iteration 0034] \n",
      "[Open3D DEBUG] Residual error : 16028.964073 (avg : 0.003407)\n",
      "[Open3D DEBUG] [Iteration 0035] \n",
      "[Open3D DEBUG] Residual error : 15858.129949 (avg : 0.003371)\n",
      "[Open3D DEBUG] [Iteration 0036] \n",
      "[Open3D DEBUG] Residual error : 15686.642635 (avg : 0.003334)\n",
      "[Open3D DEBUG] [Iteration 0037] \n",
      "[Open3D DEBUG] Residual error : 15513.719628 (avg : 0.003297)\n",
      "[Open3D DEBUG] [Iteration 0038] \n",
      "[Open3D DEBUG] Residual error : 15339.369246 (avg : 0.003260)\n",
      "[Open3D DEBUG] [Iteration 0039] \n",
      "[Open3D DEBUG] Residual error : 15163.439300 (avg : 0.003223)\n",
      "[Open3D DEBUG] [Iteration 0040] \n",
      "[Open3D DEBUG] Residual error : 14985.757900 (avg : 0.003185)\n",
      "[Open3D DEBUG] [Iteration 0041] \n",
      "[Open3D DEBUG] Residual error : 14806.617845 (avg : 0.003147)\n",
      "[Open3D DEBUG] [Iteration 0042] \n",
      "[Open3D DEBUG] Residual error : 14626.059264 (avg : 0.003109)\n",
      "[Open3D DEBUG] [Iteration 0043] \n",
      "[Open3D DEBUG] Residual error : 14443.625413 (avg : 0.003070)\n",
      "[Open3D DEBUG] [Iteration 0044] \n",
      "[Open3D DEBUG] Residual error : 14259.326270 (avg : 0.003031)\n",
      "[Open3D DEBUG] [Iteration 0045] \n",
      "[Open3D DEBUG] Residual error : 14073.449922 (avg : 0.002991)\n",
      "[Open3D DEBUG] [Iteration 0046] \n",
      "[Open3D DEBUG] Residual error : 13886.382375 (avg : 0.002952)\n",
      "[Open3D DEBUG] [Iteration 0047] \n",
      "[Open3D DEBUG] Residual error : 13697.917537 (avg : 0.002911)\n",
      "[Open3D DEBUG] [Iteration 0048] \n",
      "[Open3D DEBUG] Residual error : 13508.312134 (avg : 0.002871)\n",
      "[Open3D DEBUG] [Iteration 0049] \n",
      "[Open3D DEBUG] Residual error : 13317.338242 (avg : 0.002831)\n",
      "[Open3D DEBUG] [Iteration 0050] \n",
      "[Open3D DEBUG] Residual error : 13125.903241 (avg : 0.002790)\n",
      "[Open3D DEBUG] [Iteration 0051] \n",
      "[Open3D DEBUG] Residual error : 12934.127414 (avg : 0.002749)\n",
      "[Open3D DEBUG] [Iteration 0052] \n",
      "[Open3D DEBUG] Residual error : 12742.598063 (avg : 0.002708)\n",
      "[Open3D DEBUG] [Iteration 0053] \n",
      "[Open3D DEBUG] Residual error : 12551.614612 (avg : 0.002668)\n",
      "[Open3D DEBUG] [Iteration 0054] \n",
      "[Open3D DEBUG] Residual error : 12361.992528 (avg : 0.002628)\n",
      "[Open3D DEBUG] [Iteration 0055] \n",
      "[Open3D DEBUG] Residual error : 12174.346045 (avg : 0.002588)\n",
      "[Open3D DEBUG] [Iteration 0056] \n",
      "[Open3D DEBUG] Residual error : 11989.307660 (avg : 0.002548)\n",
      "[Open3D DEBUG] [Iteration 0057] \n",
      "[Open3D DEBUG] Residual error : 11807.571722 (avg : 0.002510)\n",
      "[Open3D DEBUG] [Iteration 0058] \n",
      "[Open3D DEBUG] Residual error : 11630.608171 (avg : 0.002472)\n",
      "[Open3D DEBUG] [Iteration 0059] \n",
      "[Open3D DEBUG] Residual error : 11459.226849 (avg : 0.002436)\n",
      "[Open3D DEBUG] [Iteration 0060] \n",
      "[Open3D DEBUG] Residual error : 11294.101928 (avg : 0.002401)\n",
      "[Open3D DEBUG] [Iteration 0061] \n",
      "[Open3D DEBUG] Residual error : 11136.617621 (avg : 0.002367)\n",
      "[Open3D DEBUG] [Iteration 0062] \n",
      "[Open3D DEBUG] Residual error : 10987.829629 (avg : 0.002335)\n",
      "[Open3D DEBUG] [Iteration 0063] \n",
      "[Open3D DEBUG] Residual error : 10846.494783 (avg : 0.002305)\n",
      "[Open3D DEBUG] [Iteration 0064] \n",
      "[Open3D DEBUG] Residual error : 10715.235101 (avg : 0.002278)\n",
      "[Open3D DEBUG] [Iteration 0065] \n",
      "[Open3D DEBUG] Residual error : 10593.381129 (avg : 0.002252)\n",
      "[Open3D DEBUG] [Iteration 0066] \n",
      "[Open3D DEBUG] Residual error : 10480.699566 (avg : 0.002228)\n",
      "[Open3D DEBUG] [Iteration 0067] \n",
      "[Open3D DEBUG] Residual error : 10378.046761 (avg : 0.002206)\n",
      "[Open3D DEBUG] [Iteration 0068] \n",
      "[Open3D DEBUG] Residual error : 10284.482360 (avg : 0.002186)\n",
      "[Open3D DEBUG] [Iteration 0069] \n",
      "[Open3D DEBUG] Residual error : 10199.318639 (avg : 0.002168)\n",
      "[Open3D DEBUG] [Iteration 0070] \n",
      "[Open3D DEBUG] Residual error : 10122.739402 (avg : 0.002152)\n",
      "[Open3D DEBUG] [Iteration 0071] \n",
      "[Open3D DEBUG] Residual error : 10053.677972 (avg : 0.002137)\n",
      "[Open3D DEBUG] [Iteration 0072] \n",
      "[Open3D DEBUG] Residual error : 9991.653715 (avg : 0.002124)\n",
      "[Open3D DEBUG] [Iteration 0073] \n",
      "[Open3D DEBUG] Residual error : 9935.956504 (avg : 0.002112)\n",
      "[Open3D DEBUG] [Iteration 0074] \n",
      "[Open3D DEBUG] Residual error : 9885.848506 (avg : 0.002101)\n",
      "[Open3D DEBUG] [Iteration 0075] \n",
      "[Open3D DEBUG] Residual error : 9840.681676 (avg : 0.002092)\n",
      "[Open3D DEBUG] [Iteration 0076] \n",
      "[Open3D DEBUG] Residual error : 9800.219243 (avg : 0.002083)\n",
      "[Open3D DEBUG] [Iteration 0077] \n",
      "[Open3D DEBUG] Residual error : 9763.323634 (avg : 0.002075)\n",
      "[Open3D DEBUG] [Iteration 0078] \n",
      "[Open3D DEBUG] Residual error : 9730.056207 (avg : 0.002068)\n",
      "[Open3D DEBUG] [Iteration 0079] \n",
      "[Open3D DEBUG] Residual error : 9699.678138 (avg : 0.002062)\n",
      "[Open3D DEBUG] [Iteration 0080] \n",
      "[Open3D DEBUG] Residual error : 9672.215074 (avg : 0.002056)\n",
      "[Open3D DEBUG] [Iteration 0081] \n",
      "[Open3D DEBUG] Residual error : 9646.627006 (avg : 0.002050)\n",
      "[Open3D DEBUG] [Iteration 0082] \n",
      "[Open3D DEBUG] Residual error : 9623.530113 (avg : 0.002045)\n",
      "[Open3D DEBUG] [Iteration 0083] \n",
      "[Open3D DEBUG] Residual error : 9601.971151 (avg : 0.002041)\n",
      "[Open3D DEBUG] [Iteration 0084] \n",
      "[Open3D DEBUG] Residual error : 9582.367893 (avg : 0.002037)\n",
      "[Open3D DEBUG] [Iteration 0085] \n",
      "[Open3D DEBUG] Residual error : 9564.142260 (avg : 0.002033)\n",
      "[Open3D DEBUG] [Iteration 0086] \n",
      "[Open3D DEBUG] Residual error : 9547.028282 (avg : 0.002029)\n",
      "[Open3D DEBUG] [Iteration 0087] \n",
      "[Open3D DEBUG] Residual error : 9531.077865 (avg : 0.002026)\n",
      "[Open3D DEBUG] [Iteration 0088] \n",
      "[Open3D DEBUG] Residual error : 9516.119413 (avg : 0.002023)\n",
      "[Open3D DEBUG] [Iteration 0089] \n",
      "[Open3D DEBUG] Residual error : 9502.171065 (avg : 0.002020)\n",
      "[Open3D DEBUG] [Iteration 0090] \n",
      "[Open3D DEBUG] Residual error : 9488.918634 (avg : 0.002017)\n",
      "[Open3D DEBUG] [Iteration 0091] \n",
      "[Open3D DEBUG] Residual error : 9476.499042 (avg : 0.002014)\n",
      "[Open3D DEBUG] [Iteration 0092] \n",
      "[Open3D DEBUG] Residual error : 9464.696972 (avg : 0.002012)\n",
      "[Open3D DEBUG] [Iteration 0093] \n",
      "[Open3D DEBUG] Residual error : 9453.515185 (avg : 0.002009)\n",
      "[Open3D DEBUG] [Iteration 0094] \n",
      "[Open3D DEBUG] Residual error : 9442.825386 (avg : 0.002007)\n",
      "[Open3D DEBUG] [Iteration 0095] \n",
      "[Open3D DEBUG] Residual error : 9432.423517 (avg : 0.002005)\n",
      "[Open3D DEBUG] [Iteration 0096] \n",
      "[Open3D DEBUG] Residual error : 9422.587274 (avg : 0.002003)\n",
      "[Open3D DEBUG] [Iteration 0097] \n",
      "[Open3D DEBUG] Residual error : 9413.130207 (avg : 0.002001)\n",
      "[Open3D DEBUG] [Iteration 0098] \n",
      "[Open3D DEBUG] Residual error : 9404.124481 (avg : 0.001999)\n",
      "[Open3D DEBUG] [Iteration 0099] \n",
      "[Open3D DEBUG] Residual error : 9395.318127 (avg : 0.001997)\n",
      "[Open3D DEBUG] [Iteration 0100] \n",
      "[Open3D DEBUG] Residual error : 9386.564204 (avg : 0.001995)\n",
      "[Open3D DEBUG] [ColorMapOptimization] Set Mesh Color\n",
      "[Open3D DEBUG] [RemoveDuplicatedVertices] 0 vertices have been removed.\n",
      "[Open3D DEBUG] [RemoveDuplicatedTriangles] 0 triangles have been removed.\n",
      "[Open3D DEBUG] [RemoveUnreferencedVertices] 734 vertices have been removed.\n",
      "[Open3D DEBUG] [RemoveDegenerateTriangles] 0 triangles have been removed.\n",
      "[Open3D DEBUG] Triangle mesh sampled from 536872 vertices and 1033745 triangles to 504121 vertices and 976218 triangles.\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: 不支持请求的转换操作。 \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: 句柄无效。 \n"
     ]
    }
   ],
   "source": [
    "# Optimize texture and save the mesh as texture_mapped.ply\n",
    "# This is implementation of following paper\n",
    "# Q.-Y. Zhou and V. Koltun,\n",
    "# Color Map Optimization for 3D Reconstruction with Consumer Depth Cameras,\n",
    "# SIGGRAPH 2014\n",
    "\n",
    "# Run rigid optimization.\n",
    "# maximum_iteration = 100 if is_ci else 300\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    mesh, camera_trajectory = o3d.pipelines.color_map.run_rigid_optimizer(\n",
    "        mesh, rgbd_images, camera_trajectory,\n",
    "        o3d.pipelines.color_map.RigidOptimizerOption(\n",
    "            maximum_iteration=100))\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh],\n",
    "                                  zoom=0.5399,\n",
    "                                  front=[0.0665, -0.1107, -0.9916],\n",
    "                                  lookat=[0.7353, 0.6537, 1.0521],\n",
    "                                  up=[0.0136, -0.9936, 0.1118])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非刚性优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D DEBUG] [ColorMapOptimization] CreateUtilImagesFromRGBD\n",
      "[Open3D DEBUG] [ColorMapOptimization] CreateDepthBoundaryMasks\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 0/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 1/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 2/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 3/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 4/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 5/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 6/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 7/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 8/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 9/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 10/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 11/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 12/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 13/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 14/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 15/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 16/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 17/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 18/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 19/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 20/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 21/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 22/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 23/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 24/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 25/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 26/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 27/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 28/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 29/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 30/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 31/33\n",
      "[Open3D DEBUG] [MakeDepthMasks] geometry::Image 32/33\n",
      "[Open3D DEBUG] [ColorMapOptimization] CreateVertexAndImageVisibility\n",
      "[Open3D DEBUG] [cam 0]: 249227/536872 (46.42205%) vertices are visible\n",
      "[Open3D DEBUG] [cam 1]: 270723/536872 (50.42599%) vertices are visible\n",
      "[Open3D DEBUG] [cam 2]: 230773/536872 (42.98473%) vertices are visible\n",
      "[Open3D DEBUG] [cam 3]: 224391/536872 (41.79600%) vertices are visible\n",
      "[Open3D DEBUG] [cam 4]: 212453/536872 (39.57237%) vertices are visible\n",
      "[Open3D DEBUG] [cam 5]: 176854/536872 (32.94156%) vertices are visible\n",
      "[Open3D DEBUG] [cam 6]: 194256/536872 (36.18293%) vertices are visible\n",
      "[Open3D DEBUG] [cam 7]: 146473/536872 (27.28267%) vertices are visible\n",
      "[Open3D DEBUG] [cam 8]: 149126/536872 (27.77683%) vertices are visible\n",
      "[Open3D DEBUG] [cam 9]: 120544/536872 (22.45302%) vertices are visible\n",
      "[Open3D DEBUG] [cam 10]: 159456/536872 (29.70093%) vertices are visible\n",
      "[Open3D DEBUG] [cam 11]: 182111/536872 (33.92075%) vertices are visible\n",
      "[Open3D DEBUG] [cam 12]: 247864/536872 (46.16817%) vertices are visible\n",
      "[Open3D DEBUG] [cam 13]: 243854/536872 (45.42125%) vertices are visible\n",
      "[Open3D DEBUG] [cam 14]: 221039/536872 (41.17164%) vertices are visible\n",
      "[Open3D DEBUG] [cam 15]: 257706/536872 (48.00139%) vertices are visible\n",
      "[Open3D DEBUG] [cam 16]: 153151/536872 (28.52654%) vertices are visible\n",
      "[Open3D DEBUG] [cam 17]: 159136/536872 (29.64133%) vertices are visible\n",
      "[Open3D DEBUG] [cam 18]: 114113/536872 (21.25516%) vertices are visible\n",
      "[Open3D DEBUG] [cam 19]: 134865/536872 (25.12051%) vertices are visible\n",
      "[Open3D DEBUG] [cam 20]: 129277/536872 (24.07967%) vertices are visible\n",
      "[Open3D DEBUG] [cam 21]: 123877/536872 (23.07384%) vertices are visible\n",
      "[Open3D DEBUG] [cam 22]: 112334/536872 (20.92380%) vertices are visible\n",
      "[Open3D DEBUG] [cam 23]: 106054/536872 (19.75406%) vertices are visible\n",
      "[Open3D DEBUG] [cam 24]: 70273/536872 (13.08934%) vertices are visible\n",
      "[Open3D DEBUG] [cam 25]: 82594/536872 (15.38430%) vertices are visible\n",
      "[Open3D DEBUG] [cam 26]: 128280/536872 (23.89396%) vertices are visible\n",
      "[Open3D DEBUG] [cam 27]: 130563/536872 (24.31920%) vertices are visible\n",
      "[Open3D DEBUG] [cam 28]: 129309/536872 (24.08563%) vertices are visible\n",
      "[Open3D DEBUG] [cam 29]: 158027/536872 (29.43476%) vertices are visible\n",
      "[Open3D DEBUG] [cam 30]: 172541/536872 (32.13820%) vertices are visible\n",
      "[Open3D DEBUG] [cam 31]: 154058/536872 (28.69548%) vertices are visible\n",
      "[Open3D DEBUG] [cam 32]: 99088/536872 (18.45654%) vertices are visible\n",
      "[Open3D DEBUG] [ColorMapOptimization] Non-Rigid Optimization\n",
      "[Open3D DEBUG] [Iteration 0001] \n",
      "[Open3D DEBUG] Residual error : 12219.409463, reg : 0.000000\n",
      "[Open3D DEBUG] [Iteration 0002] \n",
      "[Open3D DEBUG] Residual error : 11738.098182, reg : 13.917949\n",
      "[Open3D DEBUG] [Iteration 0003] \n",
      "[Open3D DEBUG] Residual error : 11305.643607, reg : 42.816618\n",
      "[Open3D DEBUG] [Iteration 0004] \n",
      "[Open3D DEBUG] Residual error : 10918.813332, reg : 78.968639\n",
      "[Open3D DEBUG] [Iteration 0005] \n",
      "[Open3D DEBUG] Residual error : 10573.282008, reg : 119.248857\n",
      "[Open3D DEBUG] [Iteration 0006] \n",
      "[Open3D DEBUG] Residual error : 10266.231727, reg : 161.993518\n",
      "[Open3D DEBUG] [Iteration 0007] \n",
      "[Open3D DEBUG] Residual error : 9994.651602, reg : 206.321346\n",
      "[Open3D DEBUG] [Iteration 0008] \n",
      "[Open3D DEBUG] Residual error : 9755.193775, reg : 251.393934\n",
      "[Open3D DEBUG] [Iteration 0009] \n",
      "[Open3D DEBUG] Residual error : 9543.846376, reg : 296.364797\n",
      "[Open3D DEBUG] [Iteration 0010] \n",
      "[Open3D DEBUG] Residual error : 9357.188969, reg : 340.856491\n",
      "[Open3D DEBUG] [Iteration 0011] \n",
      "[Open3D DEBUG] Residual error : 9192.092685, reg : 384.427386\n",
      "[Open3D DEBUG] [Iteration 0012] \n",
      "[Open3D DEBUG] Residual error : 9044.590116, reg : 427.430174\n",
      "[Open3D DEBUG] [Iteration 0013] \n",
      "[Open3D DEBUG] Residual error : 8912.308474, reg : 470.262477\n",
      "[Open3D DEBUG] [Iteration 0014] \n",
      "[Open3D DEBUG] Residual error : 8793.536352, reg : 512.533792\n",
      "[Open3D DEBUG] [Iteration 0015] \n",
      "[Open3D DEBUG] Residual error : 8685.983981, reg : 553.838998\n",
      "[Open3D DEBUG] [Iteration 0016] \n",
      "[Open3D DEBUG] Residual error : 8587.864179, reg : 594.333689\n",
      "[Open3D DEBUG] [Iteration 0017] \n",
      "[Open3D DEBUG] Residual error : 8497.926911, reg : 634.226733\n",
      "[Open3D DEBUG] [Iteration 0018] \n",
      "[Open3D DEBUG] Residual error : 8415.553582, reg : 673.262629\n",
      "[Open3D DEBUG] [Iteration 0019] \n",
      "[Open3D DEBUG] Residual error : 8339.698617, reg : 710.823110\n",
      "[Open3D DEBUG] [Iteration 0020] \n",
      "[Open3D DEBUG] Residual error : 8269.788296, reg : 746.891344\n",
      "[Open3D DEBUG] [Iteration 0021] \n",
      "[Open3D DEBUG] Residual error : 8205.175962, reg : 781.905671\n",
      "[Open3D DEBUG] [Iteration 0022] \n",
      "[Open3D DEBUG] Residual error : 8145.819129, reg : 815.374447\n",
      "[Open3D DEBUG] [Iteration 0023] \n",
      "[Open3D DEBUG] Residual error : 8090.392274, reg : 847.772555\n",
      "[Open3D DEBUG] [Iteration 0024] \n",
      "[Open3D DEBUG] Residual error : 8039.272935, reg : 878.228357\n",
      "[Open3D DEBUG] [Iteration 0025] \n",
      "[Open3D DEBUG] Residual error : 7991.235360, reg : 907.652260\n",
      "[Open3D DEBUG] [Iteration 0026] \n",
      "[Open3D DEBUG] Residual error : 7946.467818, reg : 935.692518\n",
      "[Open3D DEBUG] [Iteration 0027] \n",
      "[Open3D DEBUG] Residual error : 7904.266849, reg : 963.316839\n",
      "[Open3D DEBUG] [Iteration 0028] \n",
      "[Open3D DEBUG] Residual error : 7865.129914, reg : 989.824742\n",
      "[Open3D DEBUG] [Iteration 0029] \n",
      "[Open3D DEBUG] Residual error : 7827.801464, reg : 1015.936346\n",
      "[Open3D DEBUG] [Iteration 0030] \n",
      "[Open3D DEBUG] Residual error : 7792.384305, reg : 1041.294793\n",
      "[Open3D DEBUG] [Iteration 0031] \n",
      "[Open3D DEBUG] Residual error : 7758.293884, reg : 1066.399713\n",
      "[Open3D DEBUG] [Iteration 0032] \n",
      "[Open3D DEBUG] Residual error : 7725.480592, reg : 1090.541659\n",
      "[Open3D DEBUG] [Iteration 0033] \n",
      "[Open3D DEBUG] Residual error : 7692.987831, reg : 1114.471951\n",
      "[Open3D DEBUG] [Iteration 0034] \n",
      "[Open3D DEBUG] Residual error : 7662.118429, reg : 1137.683806\n",
      "[Open3D DEBUG] [Iteration 0035] \n",
      "[Open3D DEBUG] Residual error : 7632.939895, reg : 1160.772181\n",
      "[Open3D DEBUG] [Iteration 0036] \n",
      "[Open3D DEBUG] Residual error : 7604.799390, reg : 1183.075286\n",
      "[Open3D DEBUG] [Iteration 0037] \n",
      "[Open3D DEBUG] Residual error : 7577.027691, reg : 1205.065050\n",
      "[Open3D DEBUG] [Iteration 0038] \n",
      "[Open3D DEBUG] Residual error : 7550.057836, reg : 1226.295555\n",
      "[Open3D DEBUG] [Iteration 0039] \n",
      "[Open3D DEBUG] Residual error : 7524.371723, reg : 1247.180239\n",
      "[Open3D DEBUG] [Iteration 0040] \n",
      "[Open3D DEBUG] Residual error : 7500.377846, reg : 1267.044466\n",
      "[Open3D DEBUG] [Iteration 0041] \n",
      "[Open3D DEBUG] Residual error : 7477.983037, reg : 1286.393874\n",
      "[Open3D DEBUG] [Iteration 0042] \n",
      "[Open3D DEBUG] Residual error : 7456.448528, reg : 1304.842710\n",
      "[Open3D DEBUG] [Iteration 0043] \n",
      "[Open3D DEBUG] Residual error : 7435.973168, reg : 1323.017066\n",
      "[Open3D DEBUG] [Iteration 0044] \n",
      "[Open3D DEBUG] Residual error : 7416.670574, reg : 1340.582645\n",
      "[Open3D DEBUG] [Iteration 0045] \n",
      "[Open3D DEBUG] Residual error : 7398.311362, reg : 1357.998457\n",
      "[Open3D DEBUG] [Iteration 0046] \n",
      "[Open3D DEBUG] Residual error : 7380.679978, reg : 1374.857620\n",
      "[Open3D DEBUG] [Iteration 0047] \n",
      "[Open3D DEBUG] Residual error : 7363.572714, reg : 1391.570315\n",
      "[Open3D DEBUG] [Iteration 0048] \n",
      "[Open3D DEBUG] Residual error : 7347.553292, reg : 1407.570378\n",
      "[Open3D DEBUG] [Iteration 0049] \n",
      "[Open3D DEBUG] Residual error : 7332.039104, reg : 1423.439561\n",
      "[Open3D DEBUG] [Iteration 0050] \n",
      "[Open3D DEBUG] Residual error : 7317.365274, reg : 1438.657591\n",
      "[Open3D DEBUG] [Iteration 0051] \n",
      "[Open3D DEBUG] Residual error : 7303.051216, reg : 1453.837042\n",
      "[Open3D DEBUG] [Iteration 0052] \n",
      "[Open3D DEBUG] Residual error : 7289.325203, reg : 1468.384926\n",
      "[Open3D DEBUG] [Iteration 0053] \n",
      "[Open3D DEBUG] Residual error : 7276.009296, reg : 1482.989508\n",
      "[Open3D DEBUG] [Iteration 0054] \n",
      "[Open3D DEBUG] Residual error : 7263.114785, reg : 1497.018099\n",
      "[Open3D DEBUG] [Iteration 0055] \n",
      "[Open3D DEBUG] Residual error : 7250.626699, reg : 1511.164147\n",
      "[Open3D DEBUG] [Iteration 0056] \n",
      "[Open3D DEBUG] Residual error : 7238.652913, reg : 1524.843013\n",
      "[Open3D DEBUG] [Iteration 0057] \n",
      "[Open3D DEBUG] Residual error : 7226.846554, reg : 1538.593435\n",
      "[Open3D DEBUG] [Iteration 0058] \n",
      "[Open3D DEBUG] Residual error : 7215.280636, reg : 1551.903145\n",
      "[Open3D DEBUG] [Iteration 0059] \n",
      "[Open3D DEBUG] Residual error : 7203.936045, reg : 1565.520095\n",
      "[Open3D DEBUG] [Iteration 0060] \n",
      "[Open3D DEBUG] Residual error : 7192.995198, reg : 1578.700997\n",
      "[Open3D DEBUG] [Iteration 0061] \n",
      "[Open3D DEBUG] Residual error : 7182.103948, reg : 1591.921342\n",
      "[Open3D DEBUG] [Iteration 0062] \n",
      "[Open3D DEBUG] Residual error : 7171.855879, reg : 1604.630742\n",
      "[Open3D DEBUG] [Iteration 0063] \n",
      "[Open3D DEBUG] Residual error : 7161.562146, reg : 1617.355774\n",
      "[Open3D DEBUG] [Iteration 0064] \n",
      "[Open3D DEBUG] Residual error : 7151.758845, reg : 1629.488044\n",
      "[Open3D DEBUG] [Iteration 0065] \n",
      "[Open3D DEBUG] Residual error : 7142.100305, reg : 1641.625626\n",
      "[Open3D DEBUG] [Iteration 0066] \n",
      "[Open3D DEBUG] Residual error : 7132.826719, reg : 1653.229472\n",
      "[Open3D DEBUG] [Iteration 0067] \n",
      "[Open3D DEBUG] Residual error : 7123.704177, reg : 1664.910146\n",
      "[Open3D DEBUG] [Iteration 0068] \n",
      "[Open3D DEBUG] Residual error : 7114.863577, reg : 1676.148222\n",
      "[Open3D DEBUG] [Iteration 0069] \n",
      "[Open3D DEBUG] Residual error : 7106.177615, reg : 1687.443548\n",
      "[Open3D DEBUG] [Iteration 0070] \n",
      "[Open3D DEBUG] Residual error : 7097.934961, reg : 1698.397956\n",
      "[Open3D DEBUG] [Iteration 0071] \n",
      "[Open3D DEBUG] Residual error : 7089.657147, reg : 1709.383998\n",
      "[Open3D DEBUG] [Iteration 0072] \n",
      "[Open3D DEBUG] Residual error : 7081.596743, reg : 1720.160037\n",
      "[Open3D DEBUG] [Iteration 0073] \n",
      "[Open3D DEBUG] Residual error : 7073.597634, reg : 1730.918839\n",
      "[Open3D DEBUG] [Iteration 0074] \n",
      "[Open3D DEBUG] Residual error : 7065.908579, reg : 1741.536532\n",
      "[Open3D DEBUG] [Iteration 0075] \n",
      "[Open3D DEBUG] Residual error : 7058.337071, reg : 1751.983908\n",
      "[Open3D DEBUG] [Iteration 0076] \n",
      "[Open3D DEBUG] Residual error : 7050.963975, reg : 1762.284984\n",
      "[Open3D DEBUG] [Iteration 0077] \n",
      "[Open3D DEBUG] Residual error : 7043.798168, reg : 1772.432863\n",
      "[Open3D DEBUG] [Iteration 0078] \n",
      "[Open3D DEBUG] Residual error : 7036.825314, reg : 1782.551663\n",
      "[Open3D DEBUG] [Iteration 0079] \n",
      "[Open3D DEBUG] Residual error : 7030.028055, reg : 1792.377245\n",
      "[Open3D DEBUG] [Iteration 0080] \n",
      "[Open3D DEBUG] Residual error : 7023.041359, reg : 1802.308287\n",
      "[Open3D DEBUG] [Iteration 0081] \n",
      "[Open3D DEBUG] Residual error : 7016.342084, reg : 1811.972518\n",
      "[Open3D DEBUG] [Iteration 0082] \n",
      "[Open3D DEBUG] Residual error : 7009.728887, reg : 1821.723036\n",
      "[Open3D DEBUG] [Iteration 0083] \n",
      "[Open3D DEBUG] Residual error : 7003.492377, reg : 1831.188477\n",
      "[Open3D DEBUG] [Iteration 0084] \n",
      "[Open3D DEBUG] Residual error : 6997.146977, reg : 1840.716332\n",
      "[Open3D DEBUG] [Iteration 0085] \n",
      "[Open3D DEBUG] Residual error : 6991.111762, reg : 1850.044389\n",
      "[Open3D DEBUG] [Iteration 0086] \n",
      "[Open3D DEBUG] Residual error : 6985.083067, reg : 1859.512327\n",
      "[Open3D DEBUG] [Iteration 0087] \n",
      "[Open3D DEBUG] Residual error : 6978.925543, reg : 1868.754710\n",
      "[Open3D DEBUG] [Iteration 0088] \n",
      "[Open3D DEBUG] Residual error : 6973.144358, reg : 1877.914578\n",
      "[Open3D DEBUG] [Iteration 0089] \n",
      "[Open3D DEBUG] Residual error : 6967.202136, reg : 1887.324650\n",
      "[Open3D DEBUG] [Iteration 0090] \n",
      "[Open3D DEBUG] Residual error : 6961.490244, reg : 1896.446263\n",
      "[Open3D DEBUG] [Iteration 0091] \n",
      "[Open3D DEBUG] Residual error : 6955.739066, reg : 1905.621188\n",
      "[Open3D DEBUG] [Iteration 0092] \n",
      "[Open3D DEBUG] Residual error : 6950.256386, reg : 1914.469787\n",
      "[Open3D DEBUG] [Iteration 0093] \n",
      "[Open3D DEBUG] Residual error : 6944.474468, reg : 1922.937838\n",
      "[Open3D DEBUG] [Iteration 0094] \n",
      "[Open3D DEBUG] Residual error : 6939.090890, reg : 1931.558575\n",
      "[Open3D DEBUG] [Iteration 0095] \n",
      "[Open3D DEBUG] Residual error : 6933.843502, reg : 1939.838771\n",
      "[Open3D DEBUG] [Iteration 0096] \n",
      "[Open3D DEBUG] Residual error : 6928.335215, reg : 1948.237033\n",
      "[Open3D DEBUG] [Iteration 0097] \n",
      "[Open3D DEBUG] Residual error : 6923.186785, reg : 1956.282267\n",
      "[Open3D DEBUG] [Iteration 0098] \n",
      "[Open3D DEBUG] Residual error : 6917.679679, reg : 1964.501767\n",
      "[Open3D DEBUG] [Iteration 0099] \n",
      "[Open3D DEBUG] Residual error : 6912.341878, reg : 1972.443931\n",
      "[Open3D DEBUG] [Iteration 0100] \n",
      "[Open3D DEBUG] Residual error : 6907.042253, reg : 1980.497469\n",
      "[Open3D DEBUG] [ColorMapOptimization] Set Mesh Color\n",
      "[Open3D DEBUG] [RemoveDuplicatedVertices] 0 vertices have been removed.\n",
      "[Open3D DEBUG] [RemoveDuplicatedTriangles] 0 triangles have been removed.\n",
      "[Open3D DEBUG] [RemoveUnreferencedVertices] 768 vertices have been removed.\n",
      "[Open3D DEBUG] [RemoveDegenerateTriangles] 0 triangles have been removed.\n",
      "[Open3D DEBUG] Triangle mesh sampled from 536872 vertices and 1033745 triangles to 509770 vertices and 984365 triangles.\n"
     ]
    }
   ],
   "source": [
    "# Run non-rigid optimization.\n",
    "# maximum_iteration = 100 if is_ci else 300\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    mesh, camera_trajectory = o3d.pipelines.color_map.run_non_rigid_optimizer(\n",
    "        mesh, rgbd_images, camera_trajectory,\n",
    "        o3d.pipelines.color_map.NonRigidOptimizerOption(\n",
    "            maximum_iteration=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([mesh],\n",
    "                                  zoom=0.5399,\n",
    "                                  front=[0.0665, -0.1107, -0.9916],\n",
    "                                  lookat=[0.7353, 0.6537, 1.0521],\n",
    "                                  up=[0.0136, -0.9936, 0.1118])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
